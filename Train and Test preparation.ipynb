{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_electronics = pd.read_csv('electronics_nonull.csv')\n",
    "df_modcloth = pd.read_csv('modcloth_nonull.csv')\n",
    "\n",
    "# sort both the dataframes in the order of timestamp\n",
    "df_electronics.sort_values('timestamp',inplace=True)\n",
    "df_modcloth.sort_values('timestamp',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in electronics.csv\n",
      "Index(['item_id', 'user_id', 'rating', 'timestamp', 'model_attr', 'category',\n",
      "       'year', 'split', 'item_id_count', 'user_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in electronics.csv 1292954\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>split</th>\n",
       "      <th>item_id_count</th>\n",
       "      <th>user_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-13</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-14</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-06-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1999-07-06</td>\n",
       "      <td>Female</td>\n",
       "      <td>Portable Audio &amp; Video</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating   timestamp model_attr                category  \\\n",
       "0        0        0     5.0  1999-06-13     Female  Portable Audio & Video   \n",
       "1        0        1     5.0  1999-06-14     Female  Portable Audio & Video   \n",
       "2        0        2     3.0  1999-06-17     Female  Portable Audio & Video   \n",
       "3        0        3     1.0  1999-07-01     Female  Portable Audio & Video   \n",
       "4        0        4     2.0  1999-07-06     Female  Portable Audio & Video   \n",
       "\n",
       "   year  split  item_id_count  user_id_count  \n",
       "0  1999      0            118              1  \n",
       "1  1999      0            118              1  \n",
       "2  1999      0            118              1  \n",
       "3  1999      0            118              1  \n",
       "4  1999      0            118              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in electronics.csv\")\n",
    "print(df_electronics.columns)\n",
    "print(\"number of rows in electronics.csv\",df_electronics.shape[0])\n",
    "print(\"top 5 rows\")\n",
    "df_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in modcloth.csv\n",
      "Index(['item_id', 'user_id', 'rating', 'timestamp', 'model_attr', 'category',\n",
      "       'year', 'split', 'size', 'fit', 'user_attr', 'item_id_count',\n",
      "       'user_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in modcloth.csv 99892\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>split</th>\n",
       "      <th>size</th>\n",
       "      <th>fit</th>\n",
       "      <th>user_attr</th>\n",
       "      <th>item_id_count</th>\n",
       "      <th>user_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7443</td>\n",
       "      <td>Alex</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-21 08:00:00+00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown Size</td>\n",
       "      <td>Unknown Fit</td>\n",
       "      <td>Small</td>\n",
       "      <td>1011</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7443</td>\n",
       "      <td>carolyn.agan</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-27 08:00:00+00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown Size</td>\n",
       "      <td>Unknown Fit</td>\n",
       "      <td>Unknown User Attribute</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7443</td>\n",
       "      <td>Robyn</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-29 08:00:00+00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown Size</td>\n",
       "      <td>Unknown Fit</td>\n",
       "      <td>Small</td>\n",
       "      <td>1011</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7443</td>\n",
       "      <td>De</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-13 08:00:00+00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown Size</td>\n",
       "      <td>Unknown Fit</td>\n",
       "      <td>Unknown User Attribute</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7443</td>\n",
       "      <td>tasha</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-18 08:00:00+00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown Size</td>\n",
       "      <td>Unknown Fit</td>\n",
       "      <td>Small</td>\n",
       "      <td>1011</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id       user_id  rating                  timestamp model_attr  \\\n",
       "0     7443          Alex       4  2010-01-21 08:00:00+00:00      Small   \n",
       "1     7443  carolyn.agan       3  2010-01-27 08:00:00+00:00      Small   \n",
       "2     7443         Robyn       4  2010-01-29 08:00:00+00:00      Small   \n",
       "3     7443            De       4  2010-02-13 08:00:00+00:00      Small   \n",
       "4     7443         tasha       4  2010-02-18 08:00:00+00:00      Small   \n",
       "\n",
       "  category  year  split          size          fit               user_attr  \\\n",
       "0  Dresses  2012      0  Unknown Size  Unknown Fit                   Small   \n",
       "1  Dresses  2012      0  Unknown Size  Unknown Fit  Unknown User Attribute   \n",
       "2  Dresses  2012      0  Unknown Size  Unknown Fit                   Small   \n",
       "3  Dresses  2012      0  Unknown Size  Unknown Fit  Unknown User Attribute   \n",
       "4  Dresses  2012      0  Unknown Size  Unknown Fit                   Small   \n",
       "\n",
       "   item_id_count  user_id_count  \n",
       "0           1011             66  \n",
       "1           1011              1  \n",
       "2           1011             30  \n",
       "3           1011              1  \n",
       "4           1011             12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in modcloth.csv\")\n",
    "print(df_modcloth.columns)\n",
    "print(\"number of rows in modcloth.csv\",df_modcloth.shape[0])\n",
    "print(\"top 5 rows\")\n",
    "df_modcloth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the count of user_ids and item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to find the item_id and/or user_id that occur only once\n",
    "# such data should be always kept in training data set\n",
    "\n",
    "# find unique counts of item_id and user_id\n",
    "# code borrowed from\n",
    "#https://stackoverflow.com/questions/29791785/python-pandas-add-a-column-to-my-dataframe-that-counts-a-variable\n",
    "\n",
    "# electronics.csv\n",
    "\n",
    "df_electronics['item_id_count'] = df_electronics.groupby('item_id')['item_id'].transform('count')\n",
    "df_electronics['user_id_count'] = df_electronics.groupby('user_id')['user_id'].transform('count')\n",
    "\n",
    "# modcloth## Find the count of user_ids and item_ids.csv\n",
    "\n",
    "df_modcloth['item_id_count'] = df_modcloth.groupby('item_id')['item_id'].transform('count')\n",
    "df_modcloth['user_id_count'] = df_modcloth.groupby('user_id')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which values are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electronics.csv\n",
      "Column :  item_id  , Is numeric? :  True\n",
      "Column :  user_id  , Is numeric? :  True\n",
      "Column :  rating  , Is numeric? :  True\n",
      "Column :  timestamp  , Is numeric? :  False\n",
      "Column :  model_attr  , Is numeric? :  False\n",
      "Column :  category  , Is numeric? :  False\n",
      "Column :  year  , Is numeric? :  True\n",
      "Column :  split  , Is numeric? :  True\n",
      "Column :  item_id_count  , Is numeric? :  True\n",
      "Column :  user_id_count  , Is numeric? :  True\n",
      "\n",
      "modcloth.csv\n",
      "Column :  item_id  , Is numeric? :  True\n",
      "Column :  user_id  , Is numeric? :  False\n",
      "Column :  rating  , Is numeric? :  True\n",
      "Column :  timestamp  , Is numeric? :  False\n",
      "Column :  model_attr  , Is numeric? :  False\n",
      "Column :  category  , Is numeric? :  False\n",
      "Column :  year  , Is numeric? :  True\n",
      "Column :  split  , Is numeric? :  True\n",
      "Column :  size  , Is numeric? :  False\n",
      "Column :  fit  , Is numeric? :  False\n",
      "Column :  user_attr  , Is numeric? :  False\n",
      "Column :  item_id_count  , Is numeric? :  True\n",
      "Column :  user_id_count  , Is numeric? :  True\n"
     ]
    }
   ],
   "source": [
    "# check if values in a column are numeric\n",
    "\n",
    "def numeric_check(df):\n",
    "    for c in df.columns:\n",
    "        # below check for numeric borrowed from\n",
    "        #https://stackoverflow.com/questions/54426845/how-to-check-if-a-pandas-dataframe-contains-only-numeric-column-wise/54427157\n",
    "        is_numeric = pd.to_numeric(df[c], errors='coerce').notnull().all()\n",
    "        print(\"Column : \",c,\" , Is numeric? : \",is_numeric)\n",
    "        \n",
    "# electronics.csv\n",
    "print('electronics.csv')\n",
    "numeric_check(df_electronics)\n",
    "\n",
    "print()\n",
    "\n",
    "# modcloth.csv\n",
    "print('modcloth.csv')\n",
    "numeric_check(df_modcloth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electronics.csv\n",
      "Size of training dataset:  1251918\n",
      "Size of testing dataset:  41036\n",
      "Effective train ratio:  0.9682618252466831\n",
      "Effective test ratio:  0.031738174753316827\n",
      "\n",
      "modcloth.csv\n",
      "Size of training dataset:  92133\n",
      "Size of testing dataset:  7759\n",
      "Effective train ratio:  0.9223261122011772\n",
      "Effective test ratio:  0.07767388779882273\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# electronics.csv\n",
    "\n",
    "# do a split\n",
    "df_electronics_train = pd.DataFrame()\n",
    "df_electronics_test = pd.DataFrame()\n",
    "df_electronics_train,df_electronics_test = train_test_split(df_electronics,test_size=0.5,shuffle = False)\n",
    "\n",
    "\n",
    "# find the userids that are in test but not train\n",
    "tr = set(list(df_electronics_train.user_id))\n",
    "te = set(list(df_electronics_test.user_id))\n",
    "missing_user_id = list(set.difference(te,tr))\n",
    "\n",
    "# get the df for these userids\n",
    "df_test_missing_user_id = df_electronics_test[df_electronics_test['user_id'].isin(missing_user_id)]\n",
    "# append to training dataset\n",
    "df_electronics_train = pd.concat([df_electronics_train, df_test_missing_user_id],\n",
    "                                  ignore_index = True)\n",
    "#  and delete from test dataset\n",
    "df_electronics_test = df_electronics_test[~df_electronics_test['user_id'].isin(missing_user_id)]\n",
    "\n",
    "\n",
    "# find the itemids that are in test but not train\n",
    "tr = set(list(df_electronics_train.item_id))\n",
    "te = set(list(df_electronics_test.item_id))\n",
    "missing_item_id = list(set.difference(te,tr))\n",
    "\n",
    "# get the df for these itemids\n",
    "df_test_missing_item_id = df_electronics_test[df_electronics_test['item_id'].isin(missing_item_id)]\n",
    "# append to training dataset\n",
    "df_electronics_train = pd.concat([df_electronics_train, df_test_missing_item_id],\n",
    "                                 ignore_index = True)\n",
    "#  and delete from test dataset\n",
    "df_electronics_test = df_electronics_test[~df_electronics_test['item_id'].isin(missing_item_id)]\n",
    "\n",
    "print(\"electronics.csv\")\n",
    "print(\"Size of training dataset: \",df_electronics_train.shape[0])\n",
    "print(\"Size of testing dataset: \",df_electronics_test.shape[0])\n",
    "print(\"Effective train ratio: \",df_electronics_train.shape[0]/df_electronics.shape[0])\n",
    "print(\"Effective test ratio: \",df_electronics_test.shape[0]/df_electronics.shape[0])\n",
    "\n",
    "print()\n",
    "\n",
    "# modcloth.csv\n",
    "\n",
    "# do a split\n",
    "df_modcloth_train = pd.DataFrame()\n",
    "df_modcloth_test = pd.DataFrame()\n",
    "df_modcloth_train,df_modcloth_test = train_test_split(df_modcloth,test_size=0.125,shuffle = False)\n",
    "\n",
    "\n",
    "# find the userids that are in test but not train\n",
    "tr = set(list(df_modcloth_train.user_id))\n",
    "te = set(list(df_modcloth_test.user_id))\n",
    "missing_user_id = list(set.difference(te,tr))\n",
    "\n",
    "# get the df for these userids\n",
    "df_test_missing_user_id = df_modcloth_test[df_modcloth_test['user_id'].isin(missing_user_id)]\n",
    "# append to training dataset\n",
    "df_modcloth_train = pd.concat([df_modcloth_train, df_test_missing_user_id],\n",
    "                                  ignore_index = True)\n",
    "#  and delete from test dataset\n",
    "df_modcloth_test = df_modcloth_test[~df_modcloth_test['user_id'].isin(missing_user_id)]\n",
    "\n",
    "\n",
    "# find the itemids that are in test but not train\n",
    "tr = set(list(df_modcloth_train.item_id))\n",
    "te = set(list(df_modcloth_test.item_id))\n",
    "missing_item_id = list(set.difference(te,tr))\n",
    "\n",
    "# get the df for these itemids\n",
    "df_test_missing_item_id = df_modcloth_test[df_modcloth_test['item_id'].isin(missing_item_id)]\n",
    "# append to training dataset\n",
    "df_modcloth_train = pd.concat([df_modcloth_train, df_test_missing_item_id],\n",
    "                                 ignore_index = True)\n",
    "#  and delete from test dataset\n",
    "df_modcloth_test = df_modcloth_test[~df_modcloth_test['item_id'].isin(missing_item_id)]\n",
    "\n",
    "print(\"modcloth.csv\")\n",
    "print(\"Size of training dataset: \",df_modcloth_train.shape[0])\n",
    "print(\"Size of testing dataset: \",df_modcloth_test.shape[0])\n",
    "print(\"Effective train ratio: \",df_modcloth_train.shape[0]/df_modcloth.shape[0])\n",
    "print(\"Effective test ratio: \",df_modcloth_test.shape[0]/df_modcloth.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the categorical data and scale the scalar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessin## Split into training and test data setg import OrdinalEncoder\n",
    "import numpy as np\n",
    "## Split into training and test data set\n",
    "def one_hot_encode(col_2Darray,ohe_pretrained=None):\n",
    "      \n",
    "    if ohe_pretrained == None:\n",
    "        # init one hot encoder\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)        \n",
    "        # fit one hot encoder and transform\n",
    "        col_2Darray_ohe = ohe.fit_transform(col_2Darray)\n",
    "        # get feature names\n",
    "        col_2Darray_feat_names = ohe.get_feature_names()\n",
    "        # return\n",
    "        return ohe,col_2Darray_ohe,col_2Darray_feat_names\n",
    "        \n",
    "    else:\n",
    "        # use pretrained one hot encoder\n",
    "        ohe = ohe_pretrained\n",
    "        # transform\n",
    "        col_2Darray_ohe = ohe.transform(col_2Darray)\n",
    "        # get feature names\n",
    "        col_2Darray_feat_names = ohe.get_feature_names()   \n",
    "        # return\n",
    "        return col_2Darray_ohe,col_2Darray_feat_names\n",
    "\n",
    "\n",
    "def standard_scale(col_2Darray,scaler_pretrained=None):\n",
    "\n",
    "    if scaler_pretrained == None:\n",
    "        # init scaler\n",
    "        scaler = StandardScaler()\n",
    "        # fit scaler and transform\n",
    "        col_2Darray_scaled = scaler.fit_transform(col_2Darray)\n",
    "        # return\n",
    "        return scaler,col_2Darray_scaled\n",
    "        \n",
    "    else:\n",
    "        # use pretrained scaler\n",
    "        scaler = scaler_pretrained\n",
    "        # transform\n",
    "        col_2Darray_scaled = scaler.transform(col_2Darray)         \n",
    "        # return\n",
    "        return col_2Darray_scaled\n",
    "\n",
    "\n",
    "def ordinal_encode(col_2Darray,ordenc_pretrained=None):\n",
    "      \n",
    "    if ordenc_pretrained == None:\n",
    "        # init ordinal encoder\n",
    "        ordenc = OrdinalEncoder(dtype=np.int32)\n",
    "        # fit one hot encoder and transform\n",
    "        col_2Darray_ordenc = ordenc.fit_transform(col_2Darray)\n",
    "        # return\n",
    "        return ordenc,col_2Darray_ordenc\n",
    "        \n",
    "    else:\n",
    "        # use pretrained ordinal encoder\n",
    "        ordenc = ordenc_pretrained\n",
    "        # transform\n",
    "        col_2Darray_ordenc = ordenc.transform(col_2Darray)          \n",
    "        # return\n",
    "        return col_2Darray_ordenc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical data to numerical data\n",
    "# and scale numerical data wherever needed\n",
    "\n",
    "# electronics.csv - training dataset\n",
    "df_electronics_train_numonly = pd.DataFrame()\n",
    "\n",
    "# directly copy fields that are numeric\n",
    "df_electronics_train_numonly['item_id'] = df_electronics_train['item_id']\n",
    "df_electronics_train_numonly['user_id'] = df_electronics_train['user_id']\n",
    "df_electronics_train_numonly['rating'] = df_electronics_train['rating']\n",
    "# timestamp => not needed after ordering and split\n",
    "#df_electronics_train_numonly['timestamp'] = df_electronics_train_numonly['timestamp']\n",
    "\n",
    "# model_attr => convert to one hot encoding\n",
    "model_attr_ohe, model_attr_ohe_values, model_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_electronics_train['model_attr'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'model_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(model_attr_ohe_feat_names):\n",
    "    col_name = 'model_attr_' + str(feat_name)\n",
    "    df_electronics_train_numonly[col_name] = model_attr_ohe_values[:,ind]\n",
    "\n",
    "# category => convert to one hot encoding\n",
    "category_ohe, category_ohe_values, category_ohe_feat_names \\\n",
    "= one_hot_encode(df_electronics_train['category'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'category_<feat_name>'\n",
    "for ind,feat_name in enumerate(category_ohe_feat_names):\n",
    "    col_name = 'category_' + str(feat_name)\n",
    "    df_electronics_train_numonly[col_name] = category_ohe_values[:,ind]    \n",
    "    \n",
    "# year => standardize to have 0 mean and variance as 1\n",
    "year_scaler,year_scaled = standard_scale(df_electronics_train['year'].to_numpy().reshape(-1,1))\n",
    "df_electronics_train_numonly['year'] = year_scaled\n",
    "df_electronics_train_numonly['split'] = df_electronics_train['split']\n",
    "df_electronics_train_numonly['user_id_count'] = df_electronics_train['user_id_count']\n",
    "df_electronics_train_numonly['item_id_count'] = df_electronics_train['item_id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical data to numerical data\n",
    "# and scale numerical data wherever needed\n",
    "\n",
    "# electronics.csv - testing dataset\n",
    "df_electronics_test_numonly = pd.DataFrame()\n",
    "\n",
    "# directly copy fields that are numeric\n",
    "df_electronics_test_numonly['item_id'] = df_electronics_test['item_id']\n",
    "df_electronics_test_numonly['user_id'] = df_electronics_test['user_id']\n",
    "df_electronics_test_numonly['rating'] = df_electronics_test['rating']\n",
    "# timestamp => not needed after ordering and split\n",
    "#df_electronics_test_numonly['timestamp'] = df_electronics_test_numonly['timestamp']\n",
    "\n",
    "# model_attr => convert to one hot encoding\n",
    "model_attr_ohe_values, model_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_electronics_test['model_attr'].to_numpy().reshape(-1,1),\n",
    "                 ohe_pretrained = model_attr_ohe)\n",
    "# assign each name to each hot encoded column as 'model_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(model_attr_ohe_feat_names):\n",
    "    col_name = 'model_attr_' + str(feat_name)\n",
    "    df_electronics_test_numonly[col_name] = model_attr_ohe_values[:,ind]\n",
    "\n",
    "# category => convert to one hot encoding\n",
    "category_ohe_values, category_ohe_feat_names \\\n",
    "= one_hot_encode(df_electronics_test['category'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = category_ohe)\n",
    "# assign each name to each hot encoded column as 'category_<feat_name>'\n",
    "for ind,feat_name in enumerate(category_ohe_feat_names):\n",
    "    col_name = 'category_' + str(feat_name)\n",
    "    df_electronics_test_numonly[col_name] = category_ohe_values[:,ind]    \n",
    "    \n",
    "# year => standardize to have 0 mean and variance as 1\n",
    "year_scaled = standard_scale(df_electronics_test['year'].to_numpy().reshape(-1,1),\n",
    "                                        scaler_pretrained=year_scaler)\n",
    "df_electronics_test_numonly['year'] = year_scaled\n",
    "df_electronics_test_numonly['split'] = df_electronics_test['split']\n",
    "df_electronics_test_numonly['user_id_count'] = df_electronics_test['user_id_count']\n",
    "df_electronics_test_numonly['item_id_count'] = df_electronics_test['item_id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in df_electronics_train_numonly\n",
      "Index(['item_id', 'user_id', 'rating', 'model_attr_x0_Female',\n",
      "       'model_attr_x0_Female&Male', 'model_attr_x0_Male',\n",
      "       'category_x0_Accessories & Supplies', 'category_x0_Camera & Photo',\n",
      "       'category_x0_Car Electronics & GPS',\n",
      "       'category_x0_Computers & Accessories', 'category_x0_Headphones',\n",
      "       'category_x0_Home Audio', 'category_x0_Portable Audio & Video',\n",
      "       'category_x0_Security & Surveillance', 'category_x0_Television & Video',\n",
      "       'category_x0_Wearable Technology', 'year', 'split', 'user_id_count',\n",
      "       'item_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in df_electronics_train_numonly 1251918\n",
      "number of columns in df_electronics_train_numonly 20\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>model_attr_x0_Female</th>\n",
       "      <th>model_attr_x0_Female&amp;Male</th>\n",
       "      <th>model_attr_x0_Male</th>\n",
       "      <th>category_x0_Accessories &amp; Supplies</th>\n",
       "      <th>category_x0_Camera &amp; Photo</th>\n",
       "      <th>category_x0_Car Electronics &amp; GPS</th>\n",
       "      <th>category_x0_Computers &amp; Accessories</th>\n",
       "      <th>category_x0_Headphones</th>\n",
       "      <th>category_x0_Home Audio</th>\n",
       "      <th>category_x0_Portable Audio &amp; Video</th>\n",
       "      <th>category_x0_Security &amp; Surveillance</th>\n",
       "      <th>category_x0_Television &amp; Video</th>\n",
       "      <th>category_x0_Wearable Technology</th>\n",
       "      <th>year</th>\n",
       "      <th>split</th>\n",
       "      <th>user_id_count</th>\n",
       "      <th>item_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.247198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.247198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.247198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.247198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.247198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating  model_attr_x0_Female  model_attr_x0_Female&Male  \\\n",
       "0        0        0     5.0                   1.0                        0.0   \n",
       "1        0        1     5.0                   1.0                        0.0   \n",
       "2        0        2     3.0                   1.0                        0.0   \n",
       "3        0        3     1.0                   1.0                        0.0   \n",
       "4        0        4     2.0                   1.0                        0.0   \n",
       "\n",
       "   model_attr_x0_Male  category_x0_Accessories & Supplies  \\\n",
       "0                 0.0                                 0.0   \n",
       "1                 0.0                                 0.0   \n",
       "2                 0.0                                 0.0   \n",
       "3                 0.0                                 0.0   \n",
       "4                 0.0                                 0.0   \n",
       "\n",
       "   category_x0_Camera & Photo  category_x0_Car Electronics & GPS  \\\n",
       "0                         0.0                                0.0   \n",
       "1                         0.0                                0.0   \n",
       "2                         0.0                                0.0   \n",
       "3                         0.0                                0.0   \n",
       "4                         0.0                                0.0   \n",
       "\n",
       "   category_x0_Computers & Accessories  category_x0_Headphones  \\\n",
       "0                                  0.0                     0.0   \n",
       "1                                  0.0                     0.0   \n",
       "2                                  0.0                     0.0   \n",
       "3                                  0.0                     0.0   \n",
       "4                                  0.0                     0.0   \n",
       "\n",
       "   category_x0_Home Audio  category_x0_Portable Audio & Video  \\\n",
       "0                     0.0                                 1.0   \n",
       "1                     0.0                                 1.0   \n",
       "2                     0.0                                 1.0   \n",
       "3                     0.0                                 1.0   \n",
       "4                     0.0                                 1.0   \n",
       "\n",
       "   category_x0_Security & Surveillance  category_x0_Television & Video  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  0.0                             0.0   \n",
       "2                                  0.0                             0.0   \n",
       "3                                  0.0                             0.0   \n",
       "4                                  0.0                             0.0   \n",
       "\n",
       "   category_x0_Wearable Technology      year  split  user_id_count  \\\n",
       "0                              0.0 -5.247198      0              1   \n",
       "1                              0.0 -5.247198      0              1   \n",
       "2                              0.0 -5.247198      0              1   \n",
       "3                              0.0 -5.247198      0              1   \n",
       "4                              0.0 -5.247198      0              1   \n",
       "\n",
       "   item_id_count  \n",
       "0            118  \n",
       "1            118  \n",
       "2            118  \n",
       "3            118  \n",
       "4            118  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in df_electronics_train_numonly\")\n",
    "print(df_electronics_train_numonly.columns)\n",
    "print(\"number of rows in df_electronics_train_numonly\",df_electronics_train_numonly.shape[0])\n",
    "print(\"number of columns in df_electronics_train_numonly\",df_electronics_train_numonly.shape[1])\n",
    "print(\"top 5 rows\")\n",
    "df_electronics_train_numonly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in df_electronics_test_numonly\n",
      "Index(['item_id', 'user_id', 'rating', 'model_attr_x0_Female',\n",
      "       'model_attr_x0_Female&Male', 'model_attr_x0_Male',\n",
      "       'category_x0_Accessories & Supplies', 'category_x0_Camera & Photo',\n",
      "       'category_x0_Car Electronics & GPS',\n",
      "       'category_x0_Computers & Accessories', 'category_x0_Headphones',\n",
      "       'category_x0_Home Audio', 'category_x0_Portable Audio & Video',\n",
      "       'category_x0_Security & Surveillance', 'category_x0_Television & Video',\n",
      "       'category_x0_Wearable Technology', 'year', 'split', 'user_id_count',\n",
      "       'item_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in df_electronics_test_numonly 41036\n",
      "number of columns in df_electronics_test_numonly 20\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>model_attr_x0_Female</th>\n",
       "      <th>model_attr_x0_Female&amp;Male</th>\n",
       "      <th>model_attr_x0_Male</th>\n",
       "      <th>category_x0_Accessories &amp; Supplies</th>\n",
       "      <th>category_x0_Camera &amp; Photo</th>\n",
       "      <th>category_x0_Car Electronics &amp; GPS</th>\n",
       "      <th>category_x0_Computers &amp; Accessories</th>\n",
       "      <th>category_x0_Headphones</th>\n",
       "      <th>category_x0_Home Audio</th>\n",
       "      <th>category_x0_Portable Audio &amp; Video</th>\n",
       "      <th>category_x0_Security &amp; Surveillance</th>\n",
       "      <th>category_x0_Television &amp; Video</th>\n",
       "      <th>category_x0_Wearable Technology</th>\n",
       "      <th>year</th>\n",
       "      <th>split</th>\n",
       "      <th>user_id_count</th>\n",
       "      <th>item_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647254</th>\n",
       "      <td>4964</td>\n",
       "      <td>412146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412227</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647311</th>\n",
       "      <td>7256</td>\n",
       "      <td>181973</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647354</th>\n",
       "      <td>2340</td>\n",
       "      <td>460569</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.342363</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647375</th>\n",
       "      <td>7256</td>\n",
       "      <td>332161</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647352</th>\n",
       "      <td>6759</td>\n",
       "      <td>491112</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  user_id  rating  model_attr_x0_Female  \\\n",
       "647254     4964   412146     1.0                   0.0   \n",
       "647311     7256   181973     5.0                   1.0   \n",
       "647354     2340   460569     3.0                   0.0   \n",
       "647375     7256   332161     5.0                   1.0   \n",
       "647352     6759   491112     5.0                   0.0   \n",
       "\n",
       "        model_attr_x0_Female&Male  model_attr_x0_Male  \\\n",
       "647254                        1.0                 0.0   \n",
       "647311                        0.0                 0.0   \n",
       "647354                        1.0                 0.0   \n",
       "647375                        0.0                 0.0   \n",
       "647352                        0.0                 1.0   \n",
       "\n",
       "        category_x0_Accessories & Supplies  category_x0_Camera & Photo  \\\n",
       "647254                                 0.0                         0.0   \n",
       "647311                                 0.0                         0.0   \n",
       "647354                                 0.0                         0.0   \n",
       "647375                                 0.0                         0.0   \n",
       "647352                                 0.0                         0.0   \n",
       "\n",
       "        category_x0_Car Electronics & GPS  \\\n",
       "647254                                0.0   \n",
       "647311                                0.0   \n",
       "647354                                0.0   \n",
       "647375                                0.0   \n",
       "647352                                0.0   \n",
       "\n",
       "        category_x0_Computers & Accessories  category_x0_Headphones  \\\n",
       "647254                                  0.0                     0.0   \n",
       "647311                                  0.0                     1.0   \n",
       "647354                                  0.0                     1.0   \n",
       "647375                                  0.0                     1.0   \n",
       "647352                                  1.0                     0.0   \n",
       "\n",
       "        category_x0_Home Audio  category_x0_Portable Audio & Video  \\\n",
       "647254                     0.0                                 0.0   \n",
       "647311                     0.0                                 0.0   \n",
       "647354                     0.0                                 0.0   \n",
       "647375                     0.0                                 0.0   \n",
       "647352                     0.0                                 0.0   \n",
       "\n",
       "        category_x0_Security & Surveillance  category_x0_Television & Video  \\\n",
       "647254                                  0.0                             1.0   \n",
       "647311                                  0.0                             0.0   \n",
       "647354                                  0.0                             0.0   \n",
       "647375                                  0.0                             0.0   \n",
       "647352                                  0.0                             0.0   \n",
       "\n",
       "        category_x0_Wearable Technology      year  split  user_id_count  \\\n",
       "647254                              0.0  0.412227      2              2   \n",
       "647311                              0.0  0.789522      1              4   \n",
       "647354                              0.0 -0.342363      2              2   \n",
       "647375                              0.0  0.789522      2              2   \n",
       "647352                              0.0  0.789522      2              2   \n",
       "\n",
       "        item_id_count  \n",
       "647254            155  \n",
       "647311           3688  \n",
       "647354           5790  \n",
       "647375           3688  \n",
       "647352            486  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in df_electronics_test_numonly\")\n",
    "print(df_electronics_test_numonly.columns)\n",
    "print(\"number of rows in df_electronics_test_numonly\",df_electronics_test_numonly.shape[0])\n",
    "print(\"number of columns in df_electronics_test_numonly\",df_electronics_test_numonly.shape[1])\n",
    "print(\"top 5 rows\")\n",
    "df_electronics_test_numonly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modcloth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical data to numerical data\n",
    "# and scale numerical data wherever needed\n",
    "\n",
    "# modcloth.csv - training dataset\n",
    "df_modcloth_train_numonly = pd.DataFrame()\n",
    "\n",
    "# directly copy fields that are numeric### Electronics dataset\n",
    "df_modcloth_train_numonly['item_id'] = df_modcloth_train['item_id']\n",
    "\n",
    "# user_id => convert from strings to ordinal encoding\n",
    "user_id_ordenc, user_id_ordenc_values = ordinal_encode(df_modcloth_train['user_id'].to_numpy().reshape(-1,1))\n",
    "df_modcloth_train_numonly['user_id'] = user_id_ordenc_values\n",
    "\n",
    "df_modcloth_train_numonly['rating'] = df_modcloth_train['rating']\n",
    "# timestamp => not needed after ordering and split\n",
    "#df_modcloth_train_numonly['timestamp'] = df_modcloth_train_numonly['timestamp']\n",
    "\n",
    "# model_attr => convert to one hot encoding\n",
    "model_attr_ohe, model_attr_ohe_values, model_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_train['model_attr'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'model_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(model_attr_ohe_feat_names):\n",
    "    col_name = 'model_attr_' + str(feat_name)\n",
    "    df_modcloth_train_numonly[col_name] = model_attr_ohe_values[:,ind]\n",
    "\n",
    "# category => convert to one hot encoding\n",
    "category_ohe, category_ohe_values, category_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_train['category'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'category_<feat_name>'\n",
    "for ind,feat_name in enumerate(category_ohe_feat_names):\n",
    "    col_name = 'category_' + str(feat_name)\n",
    "    df_modcloth_train_numonly[col_name] = category_ohe_values[:,ind]    \n",
    "    \n",
    "# year => standardize to have 0 mean and variance as 1\n",
    "year_scaler,year_scaled = standard_scale(df_modcloth_train['year'].to_numpy().reshape(-1,1))\n",
    "df_modcloth_train_numonly['year'] = year_scaled\n",
    "df_modcloth_train_numonly['split'] = df_modcloth_train['split']\n",
    "\n",
    "# size => convert to one hot encoding\n",
    "size_ohe, size_ohe_values, size_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_train['size'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'size_<feat_name>'\n",
    "for ind,feat_name in enumerate(size_ohe_feat_names):\n",
    "    col_name = 'size_' + str(feat_name)\n",
    "    df_modcloth_train_numonly[col_name] = size_ohe_values[:,ind]    \n",
    "\n",
    "# fit => convert to one hot encoding\n",
    "fit_ohe, fit_ohe_values, fit_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_train['fit'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'fit_<feat_name>'\n",
    "for ind,feat_name in enumerate(fit_ohe_feat_names):\n",
    "    col_name = 'fit_' + str(feat_name)\n",
    "    df_modcloth_train_numonly[col_name] = fit_ohe_values[:,ind]    \n",
    "\n",
    "# user_attr => convert to one hot encoding\n",
    "user_attr_ohe, user_attr_ohe_values, user_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_train['user_attr'].to_numpy().reshape(-1,1))\n",
    "# assign each name to each hot encoded column as 'user_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(user_attr_ohe_feat_names):\n",
    "    col_name = 'user_attr_' + str(feat_name)\n",
    "    df_modcloth_train_numonly[col_name] = user_attr_ohe_values[:,ind]    \n",
    "    \n",
    "df_modcloth_train_numonly['user_id_count'] = df_modcloth_train['user_id_count']\n",
    "df_modcloth_train_numonly['item_id_count'] = df_modcloth_train['item_id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical data to numerical data\n",
    "# and scale numerical data wherever needed\n",
    "\n",
    "# modcloth.csv - testing dataset\n",
    "df_modcloth_test_numonly = pd.DataFrame()\n",
    "\n",
    "# directly copy fields that are numeric\n",
    "df_modcloth_test_numonly['item_id'] = df_modcloth_test['item_id']\n",
    "\n",
    "# user_id => convert from strings to ordinal encoding\n",
    "user_id_ordenc_values = ordinal_encode(df_modcloth_test['user_id'].to_numpy().reshape(-1,1),\n",
    "                                                      ordenc_pretrained = user_id_ordenc)\n",
    "df_modcloth_test_numonly['user_id'] = user_id_ordenc_values\n",
    "\n",
    "df_modcloth_test_numonly['rating'] = df_modcloth_test['rating']\n",
    "# timestamp => not needed after ordering and split\n",
    "#df_modcloth_test_numonly['timestamp'] = df_modcloth_test_numonly['timestamp']\n",
    "\n",
    "# model_attr => convert to one hot encoding\n",
    "model_attr_ohe_values, model_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_test['model_attr'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = model_attr_ohe)\n",
    "# assign each name to each hot encoded column as 'model_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(model_attr_ohe_feat_names):\n",
    "    col_name = 'model_attr_' + str(feat_name)\n",
    "    df_modcloth_test_numonly[col_name] = model_attr_ohe_values[:,ind]\n",
    "\n",
    "# category => convert to one hot encoding\n",
    "category_ohe_values, category_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_test['category'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = category_ohe)\n",
    "# assign each name to each hot encoded column as 'category_<feat_name>'\n",
    "for ind,feat_name in enumerate(category_ohe_feat_names):\n",
    "    col_name = 'category_' + str(feat_name)\n",
    "    df_modcloth_test_numonly[col_name] = category_ohe_values[:,ind]    \n",
    "    \n",
    "# year => standardize to have 0 mean and variance as 1\n",
    "year_scaled = standard_scale(df_modcloth_test['year'].to_numpy().reshape(-1,1),\n",
    "                                        scaler_pretrained = year_scaler)\n",
    "df_modcloth_test_numonly['year'] = year_scaled\n",
    "df_modcloth_test_numonly['split'] = df_modcloth_test['split']\n",
    "\n",
    "# size => convert to one hot encoding\n",
    "size_ohe_values, size_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_test['size'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = size_ohe)\n",
    "# assign each name to each hot encoded column as 'size_<feat_name>'\n",
    "for ind,feat_name in enumerate(size_ohe_feat_names):\n",
    "    col_name = 'size_' + str(feat_name)\n",
    "    df_modcloth_test_numonly[col_name] = size_ohe_values[:,ind]    \n",
    "\n",
    "# fit => convert to one hot encoding\n",
    "fit_ohe_values, fit_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_test['fit'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = fit_ohe)\n",
    "# assign each name to each hot encoded column as 'fit_<feat_name>'\n",
    "for ind,feat_name in enumerate(fit_ohe_feat_names):\n",
    "    col_name = 'fit_' + str(feat_name)\n",
    "    df_modcloth_test_numonly[col_name] = fit_ohe_values[:,ind]    \n",
    "\n",
    "# user_attr => convert to one hot encoding\n",
    "user_attr_ohe_values, user_attr_ohe_feat_names \\\n",
    "= one_hot_encode(df_modcloth_test['user_attr'].to_numpy().reshape(-1,1),\n",
    "                ohe_pretrained = user_attr_ohe)\n",
    "# assign each name to each hot encoded column as 'user_attr_<feat_name>'\n",
    "for ind,feat_name in enumerate(user_attr_ohe_feat_names):\n",
    "    col_name = 'user_attr_' + str(feat_name)\n",
    "    df_modcloth_test_numonly[col_name] = user_attr_ohe_values[:,ind]    \n",
    "    \n",
    "df_modcloth_test_numonly['user_id_count'] = df_modcloth_test['user_id_count']\n",
    "df_modcloth_test_numonly['item_id_count'] = df_modcloth_test['item_id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in df_modcloth_train_numonly\n",
      "Index(['item_id', 'user_id', 'rating', 'model_attr_x0_Small',\n",
      "       'model_attr_x0_Small&Large', 'category_x0_Bottoms',\n",
      "       'category_x0_Dresses', 'category_x0_Outerwear', 'category_x0_Tops',\n",
      "       'year', 'split', 'size_x0_0.0', 'size_x0_1.0', 'size_x0_2.0',\n",
      "       'size_x0_3.0', 'size_x0_4.0', 'size_x0_5.0', 'size_x0_6.0',\n",
      "       'size_x0_7.0', 'size_x0_8.0', 'size_x0_Unknown Size',\n",
      "       'fit_x0_Just right', 'fit_x0_Slightly large', 'fit_x0_Slightly small',\n",
      "       'fit_x0_Unknown Fit', 'fit_x0_Very large', 'fit_x0_Very small',\n",
      "       'user_attr_x0_Large', 'user_attr_x0_Small',\n",
      "       'user_attr_x0_Unknown User Attribute', 'user_id_count',\n",
      "       'item_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in df_modcloth_train_numonly 92133\n",
      "number of columns in df_modcloth_train_numonly 32\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>model_attr_x0_Small</th>\n",
       "      <th>model_attr_x0_Small&amp;Large</th>\n",
       "      <th>category_x0_Bottoms</th>\n",
       "      <th>category_x0_Dresses</th>\n",
       "      <th>category_x0_Outerwear</th>\n",
       "      <th>category_x0_Tops</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>fit_x0_Slightly large</th>\n",
       "      <th>fit_x0_Slightly small</th>\n",
       "      <th>fit_x0_Unknown Fit</th>\n",
       "      <th>fit_x0_Very large</th>\n",
       "      <th>fit_x0_Very small</th>\n",
       "      <th>user_attr_x0_Large</th>\n",
       "      <th>user_attr_x0_Small</th>\n",
       "      <th>user_attr_x0_Unknown User Attribute</th>\n",
       "      <th>user_id_count</th>\n",
       "      <th>item_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7443</td>\n",
       "      <td>309</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7443</td>\n",
       "      <td>13009</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7443</td>\n",
       "      <td>5534</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7443</td>\n",
       "      <td>1716</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7443</td>\n",
       "      <td>42071</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  user_id  rating  model_attr_x0_Small  model_attr_x0_Small&Large  \\\n",
       "0     7443      309       4                  1.0                        0.0   \n",
       "1     7443    13009       3                  1.0                        0.0   \n",
       "2     7443     5534       4                  1.0                        0.0   \n",
       "3     7443     1716       4                  1.0                        0.0   \n",
       "4     7443    42071       4                  1.0                        0.0   \n",
       "\n",
       "   category_x0_Bottoms  category_x0_Dresses  category_x0_Outerwear  \\\n",
       "0                  0.0                  1.0                    0.0   \n",
       "1                  0.0                  1.0                    0.0   \n",
       "2                  0.0                  1.0                    0.0   \n",
       "3                  0.0                  1.0                    0.0   \n",
       "4                  0.0                  1.0                    0.0   \n",
       "\n",
       "   category_x0_Tops      year  ...  fit_x0_Slightly large  \\\n",
       "0               0.0 -1.727919  ...                    0.0   \n",
       "1               0.0 -1.727919  ...                    0.0   \n",
       "2               0.0 -1.727919  ...                    0.0   \n",
       "3               0.0 -1.727919  ...                    0.0   \n",
       "4               0.0 -1.727919  ...                    0.0   \n",
       "\n",
       "   fit_x0_Slightly small  fit_x0_Unknown Fit  fit_x0_Very large  \\\n",
       "0                    0.0                 1.0                0.0   \n",
       "1                    0.0                 1.0                0.0   \n",
       "2                    0.0                 1.0                0.0   \n",
       "3                    0.0                 1.0                0.0   \n",
       "4                    0.0                 1.0                0.0   \n",
       "\n",
       "   fit_x0_Very small  user_attr_x0_Large  user_attr_x0_Small  \\\n",
       "0                0.0                 0.0                 1.0   \n",
       "1                0.0                 0.0                 0.0   \n",
       "2                0.0                 0.0                 1.0   \n",
       "3                0.0                 0.0                 0.0   \n",
       "4                0.0                 0.0                 1.0   \n",
       "\n",
       "   user_attr_x0_Unknown User Attribute  user_id_count  item_id_count  \n",
       "0                                  0.0             66           1011  \n",
       "1                                  1.0              1           1011  \n",
       "2                                  0.0             30           1011  \n",
       "3                                  1.0              1           1011  \n",
       "4                                  0.0             12           1011  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in df_modcloth_train_numonly\")\n",
    "print(df_modcloth_train_numonly.columns)\n",
    "print(\"number of rows in df_modcloth_train_numonly\",df_modcloth_train_numonly.shape[0])\n",
    "print(\"number of columns in df_modcloth_train_numonly\",df_modcloth_train_numonly.shape[1])\n",
    "print(\"top 5 rows\")\n",
    "df_modcloth_train_numonly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of columns in df_modcloth_test_numonly\n",
      "Index(['item_id', 'user_id', 'rating', 'model_attr_x0_Small',\n",
      "       'model_attr_x0_Small&Large', 'category_x0_Bottoms',\n",
      "       'category_x0_Dresses', 'category_x0_Outerwear', 'category_x0_Tops',\n",
      "       'year', 'split', 'size_x0_0.0', 'size_x0_1.0', 'size_x0_2.0',\n",
      "       'size_x0_3.0', 'size_x0_4.0', 'size_x0_5.0', 'size_x0_6.0',\n",
      "       'size_x0_7.0', 'size_x0_8.0', 'size_x0_Unknown Size',\n",
      "       'fit_x0_Just right', 'fit_x0_Slightly large', 'fit_x0_Slightly small',\n",
      "       'fit_x0_Unknown Fit', 'fit_x0_Very large', 'fit_x0_Very small',\n",
      "       'user_attr_x0_Large', 'user_attr_x0_Small',\n",
      "       'user_attr_x0_Unknown User Attribute', 'user_id_count',\n",
      "       'item_id_count'],\n",
      "      dtype='object')\n",
      "number of rows in df_modcloth_test_numonly 7759\n",
      "number of columns in df_modcloth_test_numonly 32\n",
      "top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>model_attr_x0_Small</th>\n",
       "      <th>model_attr_x0_Small&amp;Large</th>\n",
       "      <th>category_x0_Bottoms</th>\n",
       "      <th>category_x0_Dresses</th>\n",
       "      <th>category_x0_Outerwear</th>\n",
       "      <th>category_x0_Tops</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>fit_x0_Slightly large</th>\n",
       "      <th>fit_x0_Slightly small</th>\n",
       "      <th>fit_x0_Unknown Fit</th>\n",
       "      <th>fit_x0_Very large</th>\n",
       "      <th>fit_x0_Very small</th>\n",
       "      <th>user_attr_x0_Large</th>\n",
       "      <th>user_attr_x0_Small</th>\n",
       "      <th>user_attr_x0_Unknown User Attribute</th>\n",
       "      <th>user_id_count</th>\n",
       "      <th>item_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87423</th>\n",
       "      <td>80427</td>\n",
       "      <td>37440</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.191453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87410</th>\n",
       "      <td>153726</td>\n",
       "      <td>411</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87408</th>\n",
       "      <td>76049</td>\n",
       "      <td>38327</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87396</th>\n",
       "      <td>135555</td>\n",
       "      <td>1139</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87398</th>\n",
       "      <td>69630</td>\n",
       "      <td>37810</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.191453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  user_id  rating  model_attr_x0_Small  \\\n",
       "87423    80427    37440       3                  0.0   \n",
       "87410   153726      411       5                  0.0   \n",
       "87408    76049    38327       4                  0.0   \n",
       "87396   135555     1139       5                  0.0   \n",
       "87398    69630    37810       1                  1.0   \n",
       "\n",
       "       model_attr_x0_Small&Large  category_x0_Bottoms  category_x0_Dresses  \\\n",
       "87423                        1.0                  0.0                  0.0   \n",
       "87410                        1.0                  0.0                  0.0   \n",
       "87408                        1.0                  1.0                  0.0   \n",
       "87396                        1.0                  0.0                  0.0   \n",
       "87398                        0.0                  1.0                  0.0   \n",
       "\n",
       "       category_x0_Outerwear  category_x0_Tops      year  ...  \\\n",
       "87423                    0.0               1.0 -0.191453  ...   \n",
       "87410                    0.0               1.0  0.832858  ...   \n",
       "87408                    0.0               0.0  0.832858  ...   \n",
       "87396                    1.0               0.0  0.320702  ...   \n",
       "87398                    0.0               0.0 -0.191453  ...   \n",
       "\n",
       "       fit_x0_Slightly large  fit_x0_Slightly small  fit_x0_Unknown Fit  \\\n",
       "87423                    0.0                    0.0                 1.0   \n",
       "87410                    0.0                    0.0                 1.0   \n",
       "87408                    0.0                    0.0                 1.0   \n",
       "87396                    0.0                    0.0                 1.0   \n",
       "87398                    0.0                    0.0                 1.0   \n",
       "\n",
       "       fit_x0_Very large  fit_x0_Very small  user_attr_x0_Large  \\\n",
       "87423                0.0                0.0                 0.0   \n",
       "87410                0.0                0.0                 0.0   \n",
       "87408                0.0                0.0                 0.0   \n",
       "87396                0.0                0.0                 0.0   \n",
       "87398                0.0                0.0                 0.0   \n",
       "\n",
       "       user_attr_x0_Small  user_attr_x0_Unknown User Attribute  user_id_count  \\\n",
       "87423                 0.0                                  1.0              8   \n",
       "87410                 1.0                                  0.0            204   \n",
       "87408                 1.0                                  0.0             59   \n",
       "87396                 1.0                                  0.0             11   \n",
       "87398                 0.0                                  1.0              7   \n",
       "\n",
       "       item_id_count  \n",
       "87423            539  \n",
       "87410             98  \n",
       "87408            573  \n",
       "87396            117  \n",
       "87398            256  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of columns in df_modcloth_test_numonly\")\n",
    "print(df_modcloth_test_numonly.columns)\n",
    "print(\"number of rows in df_modcloth_test_numonly\",df_modcloth_test_numonly.shape[0])\n",
    "print(\"number of columns in df_modcloth_test_numonly\",df_modcloth_test_numonly.shape[1])\n",
    "print(\"top 5 rows\")\n",
    "df_modcloth_test_numonly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer data to csv\n",
    "\n",
    "df_electronics_train_numonly.to_csv('electronics_train.csv',index=False)\n",
    "df_modcloth_train_numonly.to_csv('modcloth_train.csv',index=False)\n",
    "### Electronics dataset\n",
    "df_electronics_test_numonly.to_csv('electronics_test.csv',index=False)\n",
    "df_modcloth_test_numonly.to_csv('modcloth_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
